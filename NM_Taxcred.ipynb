{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d817c194-0c65-44bf-bea7-9840b7b3cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50cf1d6a-9806-48f2-b40a-753651630ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark session started\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NM_Taxcred\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark session started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e7abfb2-39a8-4789-a224-650848e94e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in this directory:\n",
      "['.anaconda', '.android', '.conda', '.condarc', '.continuum', '.cursor', '.insomniac', '.ipynb_checkpoints', '.ipython', '.jupyter', '.popsql.json', 'anaconda3', 'anaconda_projects', 'ansel', 'AppData', 'Application Data', 'artifacts', 'Contacts', 'Cookies', 'CrossDevice', 'Documents', 'Downloads', 'Favorites', 'high_income_companies.csv', 'high_value_output.csv', 'high_value_output_1.csv', 'HP', 'IdeaProjects', 'Links', 'Local Settings', 'Music', 'My Documents', 'NetHood', 'NM_Taxcred.csv', 'NM_Taxcred.ipynb', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{a29fe300-904f-11ef-aec7-d6df598c01f7}.TM.blf', 'NTUSER.DAT{a29fe300-904f-11ef-aec7-d6df598c01f7}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{a29fe300-904f-11ef-aec7-d6df598c01f7}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OneDrive', 'output', 'PrintHood', 'Project 1.ipynb', 'raw data 1.csv', 'Recent', 'Saved Games', 'Searches', 'SendTo', 'Start Menu', 'Templates', 'Untitled.ipynb', 'Untitled1.ipynb', 'Untitled2.ipynb', 'Untitled3.ipynb', 'Untitled4.ipynb', 'Videos']\n",
      "‚úÖ File found: NM_Taxcred.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = \"NM_Taxcred.csv\"\n",
    "\n",
    "print(\"Files in this directory:\")\n",
    "print(os.listdir())\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"‚úÖ File found: {file_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2975ba77-d95f-4d30-9219-3df1714931c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ csv loaded into Dataframe\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"NM_Taxcred.csv\", header=True, inferSchema=True)\n",
    "print(\"‚úÖ csv loaded into Dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceef9cbf-9f79-4bf8-8df4-bdaf2d3c28d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- the_geom: string (nullable = true)\n",
      " |-- OBJECTID: integer (nullable = true)\n",
      " |-- New Market Tax Credit: string (nullable = true)\n",
      "\n",
      "+--------+--------+---------------------+\n",
      "|the_geom|OBJECTID|New Market Tax Credit|\n",
      "+--------+--------+---------------------+\n",
      "|NULL    |30      |Yes                  |\n",
      "|NULL    |27      |Yes                  |\n",
      "|NULL    |29      |Yes                  |\n",
      "|NULL    |15      |Yes                  |\n",
      "|NULL    |75      |Yes                  |\n",
      "+--------+--------+---------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23341db0-663c-4015-8bc3-32fb46258bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|OBJECTID|TaxCreditFlag|\n",
      "+--------+-------------+\n",
      "|      30|            1|\n",
      "|      27|            1|\n",
      "|      29|            1|\n",
      "|      15|            1|\n",
      "|      75|            1|\n",
      "+--------+-------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_cleaned = df.withColumn(\"TaxCreditFlag\",\n",
    "                           when(df[\"New Market Tax Credit\"] == \"Yes\", 1).otherwise(0)\n",
    "                                )\n",
    "df_cleaned.select(\"OBJECTID\",\"TaxCreditFlag\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20fb4ada-5463-4c51-9bdb-bdf4d35fadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"OBJECTID\"],\n",
    "               outputCol=\"features\"\n",
    ")\n",
    "\n",
    "data = assembler.transform(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5edcd2bc-037a-416d-a7c3-351c2a98e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+\n",
      "|OBJECTID|label|features|\n",
      "+--------+-----+--------+\n",
      "|30      |1    |[30.0]  |\n",
      "|27      |1    |[27.0]  |\n",
      "|29      |1    |[29.0]  |\n",
      "|15      |1    |[15.0]  |\n",
      "|75      |1    |[75.0]  |\n",
      "+--------+-----+--------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "final_data = data.withColumnRenamed(\"TaxCreditFlag\", \"label\")\n",
    "\n",
    "final_data.select(\"OBJECTID\", \"label\", \"features\").show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82eaf673-8cb3-468b-a31f-2fa0f2c41168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data split into training and test sets\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = final_data.randomSplit([0.8,0.2], seed=42)\n",
    "print(\"‚úÖ Data split into training and test sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c86724d-75db-4960-8d1f-147ee20a7e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Logistic Regression model trained\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = lr.fit(train_df)\n",
    "print(\"‚úîÔ∏è Logistic Regression model trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7742c830-4195-4b3d-a6b9-e14bd87c11ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ AUC Score: 1.000\n",
      "+-----+----------+-----------+\n",
      "|label|prediction|probability|\n",
      "+-----+----------+-----------+\n",
      "|1    |1.0       |[0.0,1.0]  |\n",
      "|1    |1.0       |[0.0,1.0]  |\n",
      "|1    |1.0       |[0.0,1.0]  |\n",
      "|1    |1.0       |[0.0,1.0]  |\n",
      "|1    |1.0       |[0.0,1.0]  |\n",
      "+-----+----------+-----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_df)\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"üéØ AUC Score: {auc:.3f}\")\n",
    "\n",
    "predictions.select(\"label\", \"prediction\",\"probability\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46b80dac-2918-4a8b-8836-0d5c9794cc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Predictions exported to tax_credit_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "export_data = predictions.select(\"OBJECTID\", \"label\", \"prediction\", \"probability\")\n",
    "\n",
    "\n",
    "export_pd = export_data.toPandas()\n",
    "\n",
    "\n",
    "export_pd.to_csv(\"tax_credit_predictions.csv\", index=False)\n",
    "\n",
    "print(\"‚úî Predictions exported to tax_credit_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09c8d22c-8eff-4dec-93f8-e9903f1f01a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_pd.to_csv(\"tax_credit_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca173d-53e4-4f4c-acf3-16d7bd8aeac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
